{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/old_alignment_eval_mistral-small_cn.csv')\n",
    "df = pd.read_csv('data/old_alignment_eval_mistral-small_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "CUTOFF = 0.459\n",
    "\n",
    "def mark_wrong_options(row):\n",
    "    scores = ast.literal_eval(row[\"SimilarityScores\"])\n",
    "    \n",
    "    cutoff = max(scores) - CUTOFF\n",
    "    \n",
    "    opts = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    values = [row[opt] for opt in opts]\n",
    "    \n",
    "    new_values = [\n",
    "        val if score >= cutoff else \"DO NOT PICK THIS OPTION\"\n",
    "        for val, score in zip(values, scores)\n",
    "    ]\n",
    "    \n",
    "    for opt, new_val in zip(opts, new_values):\n",
    "        row[opt] = new_val\n",
    "    \n",
    "    return row\n",
    "\n",
    "df = df.apply(mark_wrong_options, axis=1)\n",
    "df2 = df2.apply(mark_wrong_options, axis=1)\n",
    "\n",
    "df.to_csv(\"output/new_0.459_alignment_eval_mistral-small_en.csv\", index=False)\n",
    "df2.to_csv(\"output/new_0.459_alignment_eval_mistral-small_cn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze what we just did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_res = pd.read_csv('output/new_0.459_alignment_eval_mistral-small_en.csv')\n",
    "df2_res = pd.read_csv('output/new_0.459_alignment_eval_mistral-small_cn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DO NOT PICK THIS OPTION occurrences: 238\n",
      "Counts per option column:\n",
      "A    58\n",
      "B    53\n",
      "C    52\n",
      "D    75\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total_wrong = df1_res.isin([\"DO NOT PICK THIS OPTION\"]).sum().sum()\n",
    "\n",
    "print(f\"Total DO NOT PICK THIS OPTION occurrences: {total_wrong}\")\n",
    "\n",
    "# — if you just want to see the breakdown by column (e.g. A–D), you can do:\n",
    "col_counts = df1_res[['A','B','C','D']].isin([\"DO NOT PICK THIS OPTION\"]).sum()\n",
    "print(\"Counts per option column:\")\n",
    "print(col_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DO NOT PICK THIS OPTION occurrences: 142\n",
      "Counts per option column:\n",
      "A    34\n",
      "B    27\n",
      "C    31\n",
      "D    50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total_wrong = df2_res.isin([\"DO NOT PICK THIS OPTION\"]).sum().sum()\n",
    "\n",
    "print(f\"Total DO NOT PICK THIS OPTION occurrences: {total_wrong}\")\n",
    "\n",
    "# — if you just want to see the breakdown by column (e.g. A–D), you can do:\n",
    "col_counts = df2_res[['A','B','C','D']].isin([\"DO NOT PICK THIS OPTION\"]).sum()\n",
    "print(\"Counts per option column:\")\n",
    "print(col_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's test a lower cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/old_alignment_eval_mistral-small_cn.csv')\n",
    "df = pd.read_csv('data/old_alignment_eval_mistral-small_en.csv')\n",
    "\n",
    "CUTOFF = 0.2\n",
    "\n",
    "def mark_wrong_options(row):\n",
    "    scores = ast.literal_eval(row[\"SimilarityScores\"])\n",
    "    \n",
    "    cutoff = max(scores) - CUTOFF\n",
    "    \n",
    "    opts = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    values = [row[opt] for opt in opts]\n",
    "    \n",
    "    new_values = [\n",
    "        val if score >= cutoff else \"DO NOT PICK THIS OPTION\"\n",
    "        for val, score in zip(values, scores)\n",
    "    ]\n",
    "    \n",
    "    for opt, new_val in zip(opts, new_values):\n",
    "        row[opt] = new_val\n",
    "    \n",
    "    return row\n",
    "\n",
    "df = df.apply(mark_wrong_options, axis=1)\n",
    "df2 = df2.apply(mark_wrong_options, axis=1)\n",
    "\n",
    "df.to_csv(\"output/new_0.2_alignment_eval_mistral-small_en.csv\", index=False)\n",
    "df2.to_csv(\"output/new_0.2_alignment_eval_mistral-small_cn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_res = pd.read_csv('output/new_0.2_alignment_eval_mistral-small_en.csv')\n",
    "df2_res = pd.read_csv('output/new_0.2_alignment_eval_mistral-small_cn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DO NOT PICK THIS OPTION occurrences: 1270\n",
      "Counts per option column:\n",
      "A    320\n",
      "B    296\n",
      "C    305\n",
      "D    349\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total_wrong = df1_res.isin([\"DO NOT PICK THIS OPTION\"]).sum().sum()\n",
    "\n",
    "print(f\"Total DO NOT PICK THIS OPTION occurrences: {total_wrong}\")\n",
    "col_counts = df1_res[['A','B','C','D']].isin([\"DO NOT PICK THIS OPTION\"]).sum()\n",
    "print(\"Counts per option column:\")\n",
    "print(col_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DO NOT PICK THIS OPTION occurrences: 1254\n",
      "Counts per option column:\n",
      "A    297\n",
      "B    286\n",
      "C    306\n",
      "D    365\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total_wrong = df2_res.isin([\"DO NOT PICK THIS OPTION\"]).sum().sum()\n",
    "\n",
    "print(f\"Total DO NOT PICK THIS OPTION occurrences: {total_wrong}\")\n",
    "col_counts = df2_res[['A','B','C','D']].isin([\"DO NOT PICK THIS OPTION\"]).sum()\n",
    "print(\"Counts per option column:\")\n",
    "print(col_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5547d4917f701127e98eb3bce194a8c34fe7a92b4d5946487b5d1501ed4c53a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
